{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variables\n",
    "srcPath=r'C:\\\\NLP\\\\'\n",
    "inputDir=r'Input'\n",
    "outputDir=r'Output'\n",
    "modelDir=r'Model'\n",
    "\n",
    "#Directory Path\n",
    "trainFilesDir=r'TrainFiles'\n",
    "\n",
    "#Excel document holding degree names\n",
    "trainFileDegree=r'Degree.xlsx'\n",
    "\n",
    "#Spacy model to use\n",
    "spacyModel=r'en_core_web_lg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize lists\n",
    "train_data=[]\n",
    "entities=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check if Folder exists else Create\n",
    "#Input Folder\n",
    "if not os.path.exists(srcPath + inputDir):\n",
    "    os.makedirs(srcPath + inputDir)\n",
    "\n",
    "#Output Folder\n",
    "if not os.path.exists(srcPath + outputDir):\n",
    "    os.makedirs(srcPath + outputDir)\n",
    "    \n",
    "#Model Folder\n",
    "if not os.path.exists(srcPath + modelDir):\n",
    "    os.makedirs(srcPath + modelDir)\n",
    "    \n",
    "#TrainFiles Folder\n",
    "if not os.path.exists(srcPath + trainFilesDir):\n",
    "    os.makedirs(srcPath + trainFilesDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Degree List from  Xlsx  file\n",
    "degreeFilePath = srcPath + trainFilesDir + '\\\\' + trainFileDegree\n",
    "df = pd.read_excel(degreeFilePath, sheet_name=0, header=0)\n",
    "degreeList = df['Degree'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Degree Entities for training.\n",
    "degreeListFormat1=degreeList[0:20]\n",
    "degreeListFormat2=degreeList[21:40]\n",
    "degreeListFormat3=degreeList[41:60]\n",
    "degreeListFormat4=degreeList[61:80]\n",
    "\n",
    "\n",
    "for  item in degreeListFormat1:\n",
    "    a='completed '+ item.rstrip()\n",
    "    entities.append(( 10, len(a) ,'ORG'))\n",
    "    train_data.append((a, {\"entities\" : entities}))\n",
    "    entities=[] \n",
    "    \n",
    "    \n",
    "for item in degreeListFormat2:    \n",
    "    b= item.rstrip() + ' from Govt college'\n",
    "    entities.append((0, len(item) ,'ORG'))\n",
    "    train_data.append((b, {\"entities\" : entities}))\n",
    "    entities=[]\n",
    "    \n",
    "\n",
    "for item in degreeListFormat3:    \n",
    "    c= 'Education: ' + item.rstrip()\n",
    "    entities.append((11, len(c) ,'ORG'))\n",
    "    train_data.append((c, {\"entities\" : entities}))\n",
    "    entities=[]\n",
    "    \n",
    "    \n",
    "for item in degreeListFormat4:    \n",
    "    d= 'Under Graduate: ' + item.rstrip()\n",
    "    entities.append((16, len(d) ,'ORG'))\n",
    "    train_data.append((d, {\"entities\" : entities}))\n",
    "    entities=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define  model training function. This is Spacy Code\n",
    "def train_Model(model, output_dir, n_iter=100):\n",
    "   #Load the model, set up the pipeline and train the entity recognizer.\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "        \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "        \n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "            \n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "\n",
    "            \n",
    "    #save model to output directory\n",
    "        outputDir =output_dir\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_lg'\n",
      "Saved model to C:\\\\NLP\\\\Model\n"
     ]
    }
   ],
   "source": [
    "#Train Model with new data\n",
    "outputPath= srcPath + modelDir\n",
    "train_Model(spacyModel,outputPath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "nlp2 = spacy.load(r'C:\\NLP\\Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Bachelor of Arts in Sanskrit', 'ORG')]\n",
      "Entities [('Advanced diploma in Dredging technology', 'ORG')]\n",
      "Entities [(' Bachelor of Arts Philosophy', 'ORG')]\n",
      "Entities [('Certified in Bachelor of Ayurvedic Medicine & Surgery', 'ORG')]\n",
      "Entities [('Bachelor of Economics', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "TestDegrees = [\n",
    "    ('I am a  Bachelor of Arts in Sanskrit'),\n",
    "    ('I have completed Advanced diploma in Dredging technology'),\n",
    "    ('I posses a degree in  Bachelor of Arts Philosophy from Govt college'),\n",
    "    ('Certified in Bachelor of Ayurvedic Medicine & Surgery '),\n",
    "    ('undergrauate in Bachelor of Economics')\n",
    "]\n",
    "\n",
    "for deg in TestDegrees:\n",
    "            docDeg = nlp2(deg)\n",
    "            print('Entities', [(ent.text, ent.label_) for ent in docDeg.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
